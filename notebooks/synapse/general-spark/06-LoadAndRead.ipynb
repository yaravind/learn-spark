{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "//The generic read/write functions like spark.read, spark.write use the following property to find the format of the file. Otherwise\n",
        "//you habe to specify format like spark.read.format('parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "`%fs rm -r /poc` - Magic command to delete poc dir recursively\n",
        "\n",
        "`%fs cp -r wasbs://mlsamples@azureopendatastorage.blob.core.windows.net/diabetes /poc/diabetes` - Copy data from open dataset blob account to local SA\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "//The generic read/write functions like spark.read, spark.write use the following property to find the format of the file. Otherwise\n",
        "//you habe to specify format like spark.read.format('parquet')\n",
        "\n",
        "%%sql\n",
        "\n",
        "LOAD DATA INPATH '/poc/diabetes' INTO TABLE test.diabetes"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    }
  }
}