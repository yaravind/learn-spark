{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Shared Catalog - Spark, Serverless SQL & Dedicated SQL Pools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Azure Synapse Analytics provides a shared metadata model where creating a table in **serverless Apache Spark pool** will make it accessible from **serverless SQL pool** and **dedicated SQL pool** without duplicating the data.\n",
        "\n",
        "Azure Synapse Analytics allows the different computational workspace engines to share Lake databases and tables. Currently, the Lake databases and the tables (Parquet, Delta or CSV backed) that are created on the Apache Spark pools, Database templates or Dataverse are automatically shared with the serverless SQL pool engine.\n",
        "\n",
        "**Lake Database**\n",
        "\n",
        "A Lake database will become visible with that same name to all current and future Spark pools in the workspace, including the serverless SQL pool engine. You cannot add custom SQL objects (external tables, views, procedures, functions, schema, users) directly in a Lake database using the serverless SQL pool.\n",
        "\n",
        "\n",
        "Serverless SQL pool can automatically synchronize metadata from Apache Spark. A serverless SQL pool database will be created for each database existing in serverless Apache Spark pools.\n",
        "\n",
        "https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-storage-files-spark-tables\n",
        "\n",
        "https://docs.microsoft.com/en-us/azure/synapse-analytics/metadata/table\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Serverless SQL Pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Dedicated SQL Pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Limitations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    }
  }
}