{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install azure-storage-file-datalake"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io, os, uuid\n",
        "from azure.identity import DefaultAzureCredential, ManagedIdentityCredential\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ACCOUNT_NAME = \"xxx\"\n",
        "ACCOUNT_KEY = \"\"\n",
        "CONTAINER_NAME = \"tlfs\"\n",
        "FILE_PATH = 'poc/parquet/nyc_yellow_taxi_trips/puYear=2001/puMonth=1/'\n",
        "FILE = 'part-00493-127a558e-137b-4f6b-8c6e-904dc74a264e.c000.snappy.parquet'"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.filedatalake import DataLakeServiceClient\n",
        "\n",
        "def initialize_storage_account(storage_account_name, storage_account_key):\n",
        "    try:\n",
        "        global service_client\n",
        "\n",
        "        #credential = AccountSasCredentials(storage_account_name, storage_account_key)\n",
        "        #default_credential = DefaultAzureCredential()\n",
        "\n",
        "        service_client = DataLakeServiceClient(account_url=f\"https://{storage_account_name}.dfs.core.windows.net\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Data Lake service client: {e}\")\n",
        "        raise\n",
        "\n",
        "import pyarrow as pa\n",
        "import io\n",
        "\n",
        "def read_parquet_from_adls(container_name, parquet_file_path):\n",
        "    # Get a reference to the container\n",
        "    container_client = service_client.get_container_client(container_name)\n",
        "\n",
        "    # Get a reference to the file\n",
        "    file_client = container_client.get_file_client(parquet_file_path)\n",
        "\n",
        "    # Download the data as bytes\n",
        "    byte_stream = io.BytesIO()\n",
        "    downloader = file_client.download()\n",
        "    downloader.readinto(byte_stream)\n",
        "\n",
        "    # Read the Parquet file\n",
        "    byte_stream.seek(0)  # Reset the stream position\n",
        "    parquet_file = pa.ipc.open_file(byte_stream)\n",
        "    table = parquet_file.read_all()\n",
        "\n",
        "    return table"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_path = FILE_PATH + FILE\n",
        "print(temp_path)\n",
        "parquet_path= f'abfss://{CONTAINER_NAME}@{ACCOUNT_NAME}.dfs.core.windows.net/{temp_path}'\n",
        "print(parquet_path)\n",
        "storage_opts={'account_key':'TODO'}\n",
        "#parquet_path = \"poc/parquet/nyc_yellow_taxi_trips/puYear=2001/puMonth=1/part-00493-127a558e-137b-4f6b-8c6e-904dc74a264e.c000.snappy.parquet\"\n",
        "#df = pd.read_parquet(f'abfss://{CONTAINER_NAME}@{ACCOUNT_NAME}.dfs.core.windows.net/{parquet_path}')\n",
        "df = pd.read_parquet(path=parquet_path, storage_options=storage_opts)\n",
        "display(df)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initialize_storage_account(ACCOUNT_NAME, ACCOUNT_KEY)\n",
        "\n",
        "table = read_parquet_from_adls(CONTAINER_NAME, FILE_PATH + FILE)\n",
        "print(table.to_pandas())"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "account_url = f\"https://{ACCOUNT_NAME}.blob.core.windows.net\"\n",
        "\n",
        "try:\n",
        "    print(\"Azure Blob Storage Python quickstart sample\")\n",
        "    mi_credential = ManagedIdentityCredential(client_id=\"xxx\")\n",
        "    default_credential = DefaultAzureCredential()\n",
        "    # Create the BlobServiceClient object\n",
        "    #blob_service_client = BlobServiceClient(account_url, credential=cred)\n",
        "    #stream = blob_service_client.download_blob()# Instantiate a ContainerClient\n",
        "    container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
        "\n",
        "    \n",
        "\n",
        "except ResourceNotFoundError:\n",
        "    print(\"No blob found.\")\n",
        "except Exception as ex:\n",
        "    print('Exception:')\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_blob_to_stream(blob_service_client: BlobServiceClient, container_name):\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=PARQUET_FILE_PATH)\n",
        "\n",
        "    # readinto() downloads the blob contents to a stream and returns the number of bytes read\n",
        "    stream = io.BytesIO()\n",
        "    num_bytes = blob_client.download_blob().readinto(stream)\n",
        "    print(f\"Number of bytes: {num_bytes}\")"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_blob_to_stream(blob_service_client,CONTAINER_NAME)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}